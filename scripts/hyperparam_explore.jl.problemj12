using AugmentedGaussianProcesses
using MLDataUtils, DelimitedFiles
using DrWatson
quickactivate(joinpath(@__DIR__,".."))
# include(joinpath(srcdir(),"intro.jl"))
defaultdicthp = Dict(:nIterA=>10,:nIterVI=>10,
                    :file_name=>"heart.csv",:kernel=>RBFKernel,
                    :likelihood=>LogisticLikelihood(),
                    :AVI=>true,:VI=>true,:l=>1.0,:v=>1.0)
dict = defaultdicthp
data=  readdlm(joinpath(datadir(),"exp_raw/","heart.csv"),',');
yblah = data[:,1]; Xblah = data[:,2:end]; (N,nDim) = size(Xblah)
function run_vi_exp_hp2()#dict::Dict)
    ## Parameters and data
    # nIterA = 10#dict[:nIterA];
    # nIterVI = 10#dict[:nIterVI];
    #file_name = dict[:file_name];
    # data = readdlm(joinpath(datadir(),"exp_raw/",file_name),',');
    # y = data[:,1]; X = data[:,2:end]; N = size(X,1)
    # rescale!(X,obsdim=1);
    # if length(unique(y))!=2
        # rescale!(y,obsdim=1);
    # end
    # l = initial_lengthscale(X)
    # ktype = dict[:kernel]
    # l = dict[:l]
    # v = dict[:v]
    # ker = RBFKernel()# ktype(l,variance=v)
    # ll = LogisticLikelihood()#dict[:likelihood]
    # kfold = 3
    # nfold = 1
    # doAVI = true#dict[:AVI]
    # doVI = true#dict[:VI]
    # predic_results = DataFrame()
    # latent_results = DataFrame()
    # i = 1
    # X_train = X_test = X
    # y_train = y_test = y
    # for ((X_train,y_train),(X_test,y_test)) in kfolds((X,y),obsdim=1,k=kfold)
        ## Computing truth
        # @info "Using l=$l and v=$v, X_train:$(size(X))"
        # predic_results = hcat(predic_results,DataFrame([y_test],[:y_test]))
        ## Computing the augmented model
        # if doAVI
            # @info "Starting training of augmented model";
            # amodel = VGP(X_train,y_train,ker,likelihood,AnalyticVI(),verbose=2,optimizer=false)
            # train!(amodel,iterations=nIterA)
            # y_a,sig_a = proba_y(amodel,X_test)
            # predic_results = hcat(predic_results,DataFrame([y_a,sig_a],[:y_a,:sig_a]))
            # latent_results = hcat(latent_results,DataFrame([amodel.μ[1],diag(amodel.Σ[1])],[:μ_a,:Σ_a]))
        # end
        ## Computing the classical model
        # if doVI
            # try
            #     # @info "Starting training of classical model";
    vimodel = VGP(Xblah,yblah,RBFKernel(),LogisticLikelihood(),QuadratureVI(),verbose=2,optimizer=false)
    train!(vimodel,iterations=10)
            #     y_vi,sig_vi = proba_y(vimodel,X_test)
            #     predic_results = hcat(predic_results,DataFrame([y_vi,sig_vi],[:y_vi,:sig_vi]))
            #     latent_results = hcat(latent_results,DataFrame([vimodel.μ[1],diag(vimodel.Σ[1])],[:μ_vi,:Σ_vi]))
            # catch e
            #     continue #TODO treat error
            # end
        # end
        # i+=1
        # if i > nfold
            # break;
        # end
    # end
    # return predic_results, latent_results
end
function blah(X,y)
    vimodel = VGP(X,y,RBFKernel(),LogisticLikelihood(),QuadratureVI(),verbose=2,optimizer=false)
    train!(vimodel,iterations=10)
end
blah(X,y)
@info "Running the stuff"
# p_results, l_results = run_vi_exp_hp(defaultdicthp)
p_results, l_results = run_vi_exp_hp2()#defaultdicthp)
function merge_results(results::Vector{DataFrame})
    n = length(results)
    if n ==1
        return results[1]
    else
        colnames = names(results[1])
        m_results = DataFrame()
        for colname in colnames
            m = mean(results[i][colname] for i in 1:n)
            v= var.(eachrow(hcat([results[i][colname] for i in 1:n]...)))
            m_results = hcat(m_results,DataFrame([m,v],[Symbol(colname,"_μ"),Symbol(colname,"_σ")]))
        end
        return m_results
    end
end
merge_results(p_results)
